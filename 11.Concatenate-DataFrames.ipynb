{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1511e18",
   "metadata": {},
   "source": [
    "# Concatenate DataFrames Vertically and Horizontally\n",
    "## 1. Basic Concatenation Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc6316bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATING SAMPLE DATAFRAMES\n",
      "================================================================================\n",
      "Q1 Sales DataFrame:\n",
      "   employee_id     name department  q1_sales  q1_target\n",
      "0          101    Alice         IT     15000      14000\n",
      "1          102      Bob         HR     12000      13000\n",
      "2          103  Charlie    Finance     18000      17000\n",
      "\n",
      "Q2 Sales DataFrame:\n",
      "   employee_id     name department  q2_sales  q2_target\n",
      "0          101    Alice         IT     16000      15000\n",
      "1          102      Bob         HR     13000      14000\n",
      "2          103  Charlie    Finance     19000      18000\n",
      "3          104    David         IT     22000      20000\n",
      "\n",
      "Employee Info DataFrame:\n",
      "   employee_id   hire_date  salary location\n",
      "0          101  2020-01-15   75000      NYC\n",
      "1          102  2019-03-20   65000       LA\n",
      "2          103  2021-07-10   80000  Chicago\n",
      "3          104  2022-02-01   72000      NYC\n",
      "4          105  2023-05-15   68000       LA\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create sample datasets\n",
    "print(\"CREATING SAMPLE DATAFRAMES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Dataset 1: Q1 Sales\n",
    "q1_sales = pd.DataFrame({\n",
    "    'employee_id': [101, 102, 103],\n",
    "    'name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'department': ['IT', 'HR', 'Finance'],\n",
    "    'q1_sales': [15000, 12000, 18000],\n",
    "    'q1_target': [14000, 13000, 17000]\n",
    "})\n",
    "\n",
    "# Dataset 2: Q2 Sales\n",
    "q2_sales = pd.DataFrame({\n",
    "    'employee_id': [101, 102, 103, 104],  # Note: New employee 104\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "    'department': ['IT', 'HR', 'Finance', 'IT'],\n",
    "    'q2_sales': [16000, 13000, 19000, 22000],\n",
    "    'q2_target': [15000, 14000, 18000, 20000]\n",
    "})\n",
    "\n",
    "# Dataset 3: Employee Info\n",
    "employee_info = pd.DataFrame({\n",
    "    'employee_id': [101, 102, 103, 104, 105],\n",
    "    'hire_date': ['2020-01-15', '2019-03-20', '2021-07-10', '2022-02-01', '2023-05-15'],\n",
    "    'salary': [75000, 65000, 80000, 72000, 68000],\n",
    "    'location': ['NYC', 'LA', 'Chicago', 'NYC', 'LA']\n",
    "})\n",
    "\n",
    "print(\"Q1 Sales DataFrame:\")\n",
    "print(q1_sales)\n",
    "print(\"\\nQ2 Sales DataFrame:\")\n",
    "print(q2_sales)\n",
    "print(\"\\nEmployee Info DataFrame:\")\n",
    "print(employee_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcf79d5",
   "metadata": {},
   "source": [
    "# 2. Vertical Concatenation (Row-wise)\n",
    "## Example 2.1: Basic Vertical Concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b465d716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "VERTICAL CONCATENATION (ROW-WISE)\n",
      "================================================================================\n",
      "1. Basic vertical concatenation (all rows from both DataFrames):\n",
      "   employee_id     name department  q1_sales  q1_target  q2_sales  q2_target\n",
      "0          101    Alice         IT   15000.0    14000.0       NaN        NaN\n",
      "1          102      Bob         HR   12000.0    13000.0       NaN        NaN\n",
      "2          103  Charlie    Finance   18000.0    17000.0       NaN        NaN\n",
      "0          101    Alice         IT       NaN        NaN   16000.0    15000.0\n",
      "1          102      Bob         HR       NaN        NaN   13000.0    14000.0\n",
      "2          103  Charlie    Finance       NaN        NaN   19000.0    18000.0\n",
      "3          104    David         IT       NaN        NaN   22000.0    20000.0\n",
      "Shape: (7, 7) (rows, columns)\n",
      "Note: Duplicate rows appear because we concatenated similar data\n",
      "\n",
      "2. With ignore_index=True (new sequential index):\n",
      "   employee_id     name department  q1_sales  q1_target  q2_sales  q2_target\n",
      "0          101    Alice         IT   15000.0    14000.0       NaN        NaN\n",
      "1          102      Bob         HR   12000.0    13000.0       NaN        NaN\n",
      "2          103  Charlie    Finance   18000.0    17000.0       NaN        NaN\n",
      "3          101    Alice         IT       NaN        NaN   16000.0    15000.0\n",
      "4          102      Bob         HR       NaN        NaN   13000.0    14000.0\n",
      "5          103  Charlie    Finance       NaN        NaN   19000.0    18000.0\n",
      "6          104    David         IT       NaN        NaN   22000.0    20000.0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VERTICAL CONCATENATION (ROW-WISE)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Simple vertical concatenation\n",
    "combined_sales = pd.concat([q1_sales, q2_sales], axis=0)  # axis=0 is default\n",
    "print(\"1. Basic vertical concatenation (all rows from both DataFrames):\")\n",
    "print(combined_sales)\n",
    "print(f\"Shape: {combined_sales.shape} (rows, columns)\")\n",
    "print(f\"Note: Duplicate rows appear because we concatenated similar data\")\n",
    "\n",
    "# Reset index after concatenation\n",
    "combined_sales_reset = pd.concat([q1_sales, q2_sales], ignore_index=True)\n",
    "print(\"\\n2. With ignore_index=True (new sequential index):\")\n",
    "print(combined_sales_reset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea11b94",
   "metadata": {},
   "source": [
    "# Example 2.2: Vertical Concatenation with Different Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58cbe99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. DataFrames with different columns:\n",
      "Q1 Extra:\n",
      "   employee_id     name  q1_bonus  q1_commissions\n",
      "0          101    Alice      1500             750\n",
      "1          102      Bob      1200             600\n",
      "2          103  Charlie      1800             900\n",
      "\n",
      "Q2 Extra:\n",
      "   employee_id     name  q2_bonus  q2_vacation_days\n",
      "0          101    Alice      1600                 5\n",
      "1          102      Bob      1300                 3\n",
      "2          103  Charlie      1900                 7\n",
      "\n",
      "Concatenated (different columns filled with NaN):\n",
      "   employee_id     name  q1_bonus  q1_commissions  q2_bonus  q2_vacation_days\n",
      "0          101    Alice    1500.0           750.0       NaN               NaN\n",
      "1          102      Bob    1200.0           600.0       NaN               NaN\n",
      "2          103  Charlie    1800.0           900.0       NaN               NaN\n",
      "3          101    Alice       NaN             NaN    1600.0               5.0\n",
      "4          102      Bob       NaN             NaN    1300.0               3.0\n",
      "5          103  Charlie       NaN             NaN    1900.0               7.0\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrames with different columns\n",
    "q1_extra = pd.DataFrame({\n",
    "    'employee_id': [101, 102, 103],\n",
    "    'name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'q1_bonus': [1500, 1200, 1800],\n",
    "    'q1_commissions': [750, 600, 900]\n",
    "})\n",
    "\n",
    "q2_extra = pd.DataFrame({\n",
    "    'employee_id': [101, 102, 103],\n",
    "    'name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'q2_bonus': [1600, 1300, 1900],\n",
    "    'q2_vacation_days': [5, 3, 7]\n",
    "})\n",
    "\n",
    "print(\"\\n3. DataFrames with different columns:\")\n",
    "print(\"Q1 Extra:\")\n",
    "print(q1_extra)\n",
    "print(\"\\nQ2 Extra:\")\n",
    "print(q2_extra)\n",
    "\n",
    "# Concatenate with different columns\n",
    "combined_different = pd.concat([q1_extra, q2_extra], ignore_index=True)\n",
    "print(\"\\nConcatenated (different columns filled with NaN):\")\n",
    "print(combined_different)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b8d26d",
   "metadata": {},
   "source": [
    "# Example 2.3: Vertical Concatenation with keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab1466c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. Vertical concatenation with keys (multi-level index):\n",
      "             employee_id     name department  q1_sales  q1_target  q2_sales  \\\n",
      "Quarter Row                                                                   \n",
      "Q1      0            101    Alice         IT   15000.0    14000.0       NaN   \n",
      "        1            102      Bob         HR   12000.0    13000.0       NaN   \n",
      "        2            103  Charlie    Finance   18000.0    17000.0       NaN   \n",
      "Q2      0            101    Alice         IT       NaN        NaN   16000.0   \n",
      "        1            102      Bob         HR       NaN        NaN   13000.0   \n",
      "        2            103  Charlie    Finance       NaN        NaN   19000.0   \n",
      "        3            104    David         IT       NaN        NaN   22000.0   \n",
      "\n",
      "             q2_target  \n",
      "Quarter Row             \n",
      "Q1      0          NaN  \n",
      "        1          NaN  \n",
      "        2          NaN  \n",
      "Q2      0      15000.0  \n",
      "        1      14000.0  \n",
      "        2      18000.0  \n",
      "        3      20000.0  \n",
      "\n",
      "Index levels: ['Quarter', 'Row']\n",
      "\n",
      "Accessing Q1 data:\n",
      "     employee_id     name department  q1_sales  q1_target  q2_sales  q2_target\n",
      "Row                                                                           \n",
      "0            101    Alice         IT   15000.0    14000.0       NaN        NaN\n",
      "1            102      Bob         HR   12000.0    13000.0       NaN        NaN\n",
      "2            103  Charlie    Finance   18000.0    17000.0       NaN        NaN\n",
      "\n",
      "Accessing Q2 data:\n",
      "     employee_id     name department  q1_sales  q1_target  q2_sales  q2_target\n",
      "Row                                                                           \n",
      "0            101    Alice         IT       NaN        NaN   16000.0    15000.0\n",
      "1            102      Bob         HR       NaN        NaN   13000.0    14000.0\n",
      "2            103  Charlie    Finance       NaN        NaN   19000.0    18000.0\n",
      "3            104    David         IT       NaN        NaN   22000.0    20000.0\n"
     ]
    }
   ],
   "source": [
    "# Concatenate with keys for multi-level index\n",
    "combined_with_keys = pd.concat([q1_sales, q2_sales], \n",
    "                               keys=['Q1', 'Q2'], \n",
    "                               names=['Quarter', 'Row'])\n",
    "print(\"\\n4. Vertical concatenation with keys (multi-level index):\")\n",
    "print(combined_with_keys)\n",
    "print(f\"\\nIndex levels: {combined_with_keys.index.names}\")\n",
    "\n",
    "# Access data by key\n",
    "print(\"\\nAccessing Q1 data:\")\n",
    "print(combined_with_keys.loc['Q1'])\n",
    "\n",
    "print(\"\\nAccessing Q2 data:\")\n",
    "print(combined_with_keys.loc['Q2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d64633",
   "metadata": {},
   "source": [
    "# 3. Horizontal Concatenation (Column-wise)\n",
    "## Example 3.1: Basic Horizontal Concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8101b4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "HORIZONTAL CONCATENATION (COLUMN-WISE)\n",
      "================================================================================\n",
      "Employee Personal Info:\n",
      "   employee_id     name  age  education\n",
      "0          101    Alice   28    Masters\n",
      "1          102      Bob   35  Bachelors\n",
      "2          103  Charlie   42        PhD\n",
      "3          104    David   31    Masters\n",
      "\n",
      "Employee Professional Info:\n",
      "   employee_id   position  years_exp certifications\n",
      "0          101  Developer          5     AWS,Python\n",
      "1          102    Manager          8      PMP,Scrum\n",
      "2          103    Analyst         12        CFA,CPA\n",
      "3          104  Developer          4     Azure,Java\n",
      "\n",
      "1. Basic horizontal concatenation (axis=1):\n",
      "   employee_id     name  age  education  employee_id   position  years_exp  \\\n",
      "0          101    Alice   28    Masters          101  Developer          5   \n",
      "1          102      Bob   35  Bachelors          102    Manager          8   \n",
      "2          103  Charlie   42        PhD          103    Analyst         12   \n",
      "3          104    David   31    Masters          104  Developer          4   \n",
      "\n",
      "  certifications  \n",
      "0     AWS,Python  \n",
      "1      PMP,Scrum  \n",
      "2        CFA,CPA  \n",
      "3     Azure,Java  \n",
      "Note: Duplicate employee_id column\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"HORIZONTAL CONCATENATION (COLUMN-WISE)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create DataFrames with same index/rows but different columns\n",
    "employee_personal = pd.DataFrame({\n",
    "    'employee_id': [101, 102, 103, 104],\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "    'age': [28, 35, 42, 31],\n",
    "    'education': ['Masters', 'Bachelors', 'PhD', 'Masters']\n",
    "})\n",
    "\n",
    "employee_professional = pd.DataFrame({\n",
    "    'employee_id': [101, 102, 103, 104],\n",
    "    'position': ['Developer', 'Manager', 'Analyst', 'Developer'],\n",
    "    'years_exp': [5, 8, 12, 4],\n",
    "    'certifications': ['AWS,Python', 'PMP,Scrum', 'CFA,CPA', 'Azure,Java']\n",
    "})\n",
    "\n",
    "print(\"Employee Personal Info:\")\n",
    "print(employee_personal)\n",
    "print(\"\\nEmployee Professional Info:\")\n",
    "print(employee_professional)\n",
    "\n",
    "# Horizontal concatenation\n",
    "employee_complete = pd.concat([employee_personal, employee_professional], axis=1)\n",
    "print(\"\\n1. Basic horizontal concatenation (axis=1):\")\n",
    "print(employee_complete)\n",
    "print(f\"Note: Duplicate employee_id column\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0382231f",
   "metadata": {},
   "source": [
    "# Example 3.2: Horizontal Concatenation with Different Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c86ea82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. DataFrames with different indices:\n",
      "Sales Q1 (index: 101, 102, 103):\n",
      "     q1_sales  q1_target\n",
      "101     15000      14000\n",
      "102     12000      13000\n",
      "103     18000      17000\n",
      "\n",
      "Sales Q2 (index: 101, 102, 103, 104):\n",
      "     q2_sales  q2_target\n",
      "101     16000      15000\n",
      "102     13000      14000\n",
      "103     19000      18000\n",
      "104     22000      20000\n",
      "\n",
      "Horizontal concatenation (different indices - NaN for missing):\n",
      "     q1_sales  q1_target  q2_sales  q2_target\n",
      "101   15000.0    14000.0     16000      15000\n",
      "102   12000.0    13000.0     13000      14000\n",
      "103   18000.0    17000.0     19000      18000\n",
      "104       NaN        NaN     22000      20000\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrames with different indices\n",
    "sales_q1 = pd.DataFrame({\n",
    "    'q1_sales': [15000, 12000, 18000],\n",
    "    'q1_target': [14000, 13000, 17000]\n",
    "}, index=[101, 102, 103])  # employee_id as index\n",
    "\n",
    "sales_q2 = pd.DataFrame({\n",
    "    'q2_sales': [16000, 13000, 19000, 22000],\n",
    "    'q2_target': [15000, 14000, 18000, 20000]\n",
    "}, index=[101, 102, 103, 104])  # Different set of indices\n",
    "\n",
    "print(\"\\n2. DataFrames with different indices:\")\n",
    "print(\"Sales Q1 (index: 101, 102, 103):\")\n",
    "print(sales_q1)\n",
    "print(\"\\nSales Q2 (index: 101, 102, 103, 104):\")\n",
    "print(sales_q2)\n",
    "\n",
    "# Horizontal concatenation with different indices\n",
    "sales_combined = pd.concat([sales_q1, sales_q2], axis=1)\n",
    "print(\"\\nHorizontal concatenation (different indices - NaN for missing):\")\n",
    "print(sales_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed55bae",
   "metadata": {},
   "source": [
    "# Example 3.3: Horizontal Concatenation with join parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e14d615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. Horizontal concatenation with join parameter:\n",
      "Inner join (only common indices 101, 102, 103):\n",
      "     q1_sales  q1_target  q2_sales  q2_target\n",
      "101     15000      14000     16000      15000\n",
      "102     12000      13000     13000      14000\n",
      "103     18000      17000     19000      18000\n",
      "\n",
      "Outer join (all indices 101, 102, 103, 104):\n",
      "     q1_sales  q1_target  q2_sales  q2_target\n",
      "101   15000.0    14000.0     16000      15000\n",
      "102   12000.0    13000.0     13000      14000\n",
      "103   18000.0    17000.0     19000      18000\n",
      "104       NaN        NaN     22000      20000\n"
     ]
    }
   ],
   "source": [
    "# Using join parameter to control how indices are combined\n",
    "print(\"\\n3. Horizontal concatenation with join parameter:\")\n",
    "\n",
    "# Inner join (intersection of indices)\n",
    "inner_join = pd.concat([sales_q1, sales_q2], axis=1, join='inner')\n",
    "print(\"Inner join (only common indices 101, 102, 103):\")\n",
    "print(inner_join)\n",
    "\n",
    "# Outer join (union of indices) - default\n",
    "outer_join = pd.concat([sales_q1, sales_q2], axis=1, join='outer')\n",
    "print(\"\\nOuter join (all indices 101, 102, 103, 104):\")\n",
    "print(outer_join)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfc4702",
   "metadata": {},
   "source": [
    "\n",
    "# 4. Real-World Business Examples\n",
    "## Example 4.1: Monthly Sales Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d8d8180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "REAL-WORLD EXAMPLE: MONTHLY SALES REPORTS\n",
      "================================================================================\n",
      "January Sales:\n",
      "  product_id product_name  jan_units  jan_revenue\n",
      "0       P001       Laptop        150       150000\n",
      "1       P002        Mouse        300         9000\n",
      "2       P003     Keyboard        200        16000\n",
      "\n",
      "February Sales:\n",
      "  product_id product_name  feb_units  feb_revenue\n",
      "0       P001       Laptop        180       180000\n",
      "1       P002        Mouse        320         9600\n",
      "2       P004      Monitor         90        27000\n",
      "\n",
      "March Sales:\n",
      "  product_id product_name  mar_units  mar_revenue\n",
      "0       P001       Laptop        200       200000\n",
      "1       P003     Keyboard        220        17600\n",
      "2       P004      Monitor        100        30000\n",
      "3       P005   Headphones        150        22500\n",
      "\n",
      "1. Monthly Comparison (horizontal concatenation):\n",
      "           product_name  jan_units  jan_revenue product_name  feb_units  \\\n",
      "product_id                                                                \n",
      "P001             Laptop      150.0     150000.0       Laptop      180.0   \n",
      "P002              Mouse      300.0       9000.0        Mouse      320.0   \n",
      "P003           Keyboard      200.0      16000.0          NaN        NaN   \n",
      "P004                NaN        NaN          NaN      Monitor       90.0   \n",
      "P005                NaN        NaN          NaN          NaN        NaN   \n",
      "\n",
      "            feb_revenue product_name  mar_units  mar_revenue  \n",
      "product_id                                                    \n",
      "P001           180000.0       Laptop      200.0     200000.0  \n",
      "P002             9600.0          NaN        NaN          NaN  \n",
      "P003                NaN     Keyboard      220.0      17600.0  \n",
      "P004            27000.0      Monitor      100.0      30000.0  \n",
      "P005                NaN   Headphones      150.0      22500.0  \n",
      "\n",
      "2. All Months Data (vertical concatenation):\n",
      "  product_id product_name  jan_units  jan_revenue     month  feb_units  \\\n",
      "3       P001       Laptop        NaN          NaN  February      180.0   \n",
      "0       P001       Laptop      150.0     150000.0   January        NaN   \n",
      "6       P001       Laptop        NaN          NaN     March        NaN   \n",
      "4       P002        Mouse        NaN          NaN  February      320.0   \n",
      "1       P002        Mouse      300.0       9000.0   January        NaN   \n",
      "2       P003     Keyboard      200.0      16000.0   January        NaN   \n",
      "7       P003     Keyboard        NaN          NaN     March        NaN   \n",
      "5       P004      Monitor        NaN          NaN  February       90.0   \n",
      "8       P004      Monitor        NaN          NaN     March        NaN   \n",
      "9       P005   Headphones        NaN          NaN     March        NaN   \n",
      "\n",
      "   feb_revenue  mar_units  mar_revenue  \n",
      "3     180000.0        NaN          NaN  \n",
      "0          NaN        NaN          NaN  \n",
      "6          NaN      200.0     200000.0  \n",
      "4       9600.0        NaN          NaN  \n",
      "1          NaN        NaN          NaN  \n",
      "2          NaN        NaN          NaN  \n",
      "7          NaN      220.0      17600.0  \n",
      "5      27000.0        NaN          NaN  \n",
      "8          NaN      100.0      30000.0  \n",
      "9          NaN      150.0      22500.0  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"REAL-WORLD EXAMPLE: MONTHLY SALES REPORTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create monthly sales data\n",
    "jan_sales = pd.DataFrame({\n",
    "    'product_id': ['P001', 'P002', 'P003'],\n",
    "    'product_name': ['Laptop', 'Mouse', 'Keyboard'],\n",
    "    'jan_units': [150, 300, 200],\n",
    "    'jan_revenue': [150000, 9000, 16000]\n",
    "})\n",
    "\n",
    "feb_sales = pd.DataFrame({\n",
    "    'product_id': ['P001', 'P002', 'P004'],  # P003 missing, P004 new\n",
    "    'product_name': ['Laptop', 'Mouse', 'Monitor'],\n",
    "    'feb_units': [180, 320, 90],\n",
    "    'feb_revenue': [180000, 9600, 27000]\n",
    "})\n",
    "\n",
    "mar_sales = pd.DataFrame({\n",
    "    'product_id': ['P001', 'P003', 'P004', 'P005'],  # P002 missing, P005 new\n",
    "    'product_name': ['Laptop', 'Keyboard', 'Monitor', 'Headphones'],\n",
    "    'mar_units': [200, 220, 100, 150],\n",
    "    'mar_revenue': [200000, 17600, 30000, 22500]\n",
    "})\n",
    "\n",
    "print(\"January Sales:\")\n",
    "print(jan_sales)\n",
    "print(\"\\nFebruary Sales:\")\n",
    "print(feb_sales)\n",
    "print(\"\\nMarch Sales:\")\n",
    "print(mar_sales)\n",
    "\n",
    "# Method 1: Horizontal concatenation (side-by-side months)\n",
    "monthly_comparison = pd.concat([jan_sales.set_index('product_id'),\n",
    "                                feb_sales.set_index('product_id'),\n",
    "                                mar_sales.set_index('product_id')], \n",
    "                               axis=1, join='outer')\n",
    "print(\"\\n1. Monthly Comparison (horizontal concatenation):\")\n",
    "print(monthly_comparison)\n",
    "\n",
    "# Method 2: Vertical concatenation (stacked data)\n",
    "all_months = pd.concat([jan_sales.assign(month='January'),\n",
    "                        feb_sales.assign(month='February'),\n",
    "                        mar_sales.assign(month='March')], \n",
    "                       ignore_index=True)\n",
    "print(\"\\n2. All Months Data (vertical concatenation):\")\n",
    "print(all_months.sort_values(['product_id', 'month']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748537ac",
   "metadata": {},
   "source": [
    "# Example 4.2: Customer Data from Multiple Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "115d6f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "REAL-WORLD EXAMPLE: CUSTOMER DATA INTEGRATION\n",
      "================================================================================\n",
      "CRM Data (Customer Info):\n",
      "  customer_id           name              email     phone signup_date\n",
      "0        C001    Alice Smith    alice@email.com  555-0101  2023-01-15\n",
      "1        C002    Bob Johnson      bob@email.com  555-0102  2023-02-20\n",
      "2        C003  Charlie Brown  charlie@email.com  555-0103  2023-03-10\n",
      "3        C004   Diana Prince    diana@email.com  555-0104  2023-04-05\n",
      "\n",
      "Orders Data:\n",
      "  customer_id order_id  order_date  order_amount product_category\n",
      "0        C001    O1001  2023-05-10        150.50      Electronics\n",
      "1        C001    O1002  2023-06-15         89.99            Books\n",
      "2        C002    O1003  2023-05-22        299.99         Clothing\n",
      "3        C003    O1004  2023-06-01         45.50             Home\n",
      "4        C004    O1005  2023-06-20        599.99      Electronics\n",
      "5        C005    O1006  2023-06-25        129.99           Sports\n",
      "\n",
      "Support Tickets Data:\n",
      "  customer_id ticket_id  issue_date issue_type    status\n",
      "0        C001      T001  2023-04-01    Billing  Resolved\n",
      "1        C002      T002  2023-05-15  Technical      Open\n",
      "2        C002      T003  2023-06-10    Returns  Resolved\n",
      "3        C004      T004  2023-06-18  Technical      Open\n",
      "\n",
      "Customer 360 View (horizontal concatenation):\n",
      "                      name              email     phone signup_date  \\\n",
      "customer_id                                                           \n",
      "C001           Alice Smith    alice@email.com  555-0101  2023-01-15   \n",
      "C002           Bob Johnson      bob@email.com  555-0102  2023-02-20   \n",
      "C003         Charlie Brown  charlie@email.com  555-0103  2023-03-10   \n",
      "C004          Diana Prince    diana@email.com  555-0104  2023-04-05   \n",
      "C005                   NaN                NaN       NaN         NaN   \n",
      "\n",
      "             total_orders  total_spent  ticket_count         issue_types  \n",
      "customer_id                                                               \n",
      "C001                    2       240.49           1.0             Billing  \n",
      "C002                    1       299.99           2.0  Returns, Technical  \n",
      "C003                    1        45.50           NaN                 NaN  \n",
      "C004                    1       599.99           1.0           Technical  \n",
      "C005                    1       129.99           NaN                 NaN  \n",
      "\n",
      "All Unique Customer IDs (vertical concatenation):\n",
      "  customer_id\n",
      "0        C001\n",
      "1        C002\n",
      "2        C003\n",
      "3        C004\n",
      "4        C005\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"REAL-WORLD EXAMPLE: CUSTOMER DATA INTEGRATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Data from different systems\n",
    "crm_data = pd.DataFrame({\n",
    "    'customer_id': ['C001', 'C002', 'C003', 'C004'],\n",
    "    'name': ['Alice Smith', 'Bob Johnson', 'Charlie Brown', 'Diana Prince'],\n",
    "    'email': ['alice@email.com', 'bob@email.com', 'charlie@email.com', 'diana@email.com'],\n",
    "    'phone': ['555-0101', '555-0102', '555-0103', '555-0104'],\n",
    "    'signup_date': ['2023-01-15', '2023-02-20', '2023-03-10', '2023-04-05']\n",
    "})\n",
    "\n",
    "orders_data = pd.DataFrame({\n",
    "    'customer_id': ['C001', 'C001', 'C002', 'C003', 'C004', 'C005'],  # C005 not in CRM\n",
    "    'order_id': ['O1001', 'O1002', 'O1003', 'O1004', 'O1005', 'O1006'],\n",
    "    'order_date': ['2023-05-10', '2023-06-15', '2023-05-22', '2023-06-01', '2023-06-20', '2023-06-25'],\n",
    "    'order_amount': [150.50, 89.99, 299.99, 45.50, 599.99, 129.99],\n",
    "    'product_category': ['Electronics', 'Books', 'Clothing', 'Home', 'Electronics', 'Sports']\n",
    "})\n",
    "\n",
    "support_data = pd.DataFrame({\n",
    "    'customer_id': ['C001', 'C002', 'C002', 'C004'],\n",
    "    'ticket_id': ['T001', 'T002', 'T003', 'T004'],\n",
    "    'issue_date': ['2023-04-01', '2023-05-15', '2023-06-10', '2023-06-18'],\n",
    "    'issue_type': ['Billing', 'Technical', 'Returns', 'Technical'],\n",
    "    'status': ['Resolved', 'Open', 'Resolved', 'Open']\n",
    "})\n",
    "\n",
    "print(\"CRM Data (Customer Info):\")\n",
    "print(crm_data)\n",
    "print(\"\\nOrders Data:\")\n",
    "print(orders_data)\n",
    "print(\"\\nSupport Tickets Data:\")\n",
    "print(support_data)\n",
    "\n",
    "# Strategy 1: Combine all data horizontally\n",
    "# First, aggregate orders and support data\n",
    "orders_summary = orders_data.groupby('customer_id').agg({\n",
    "    'order_id': 'count',\n",
    "    'order_amount': 'sum'\n",
    "}).rename(columns={'order_id': 'total_orders', 'order_amount': 'total_spent'})\n",
    "\n",
    "support_summary = support_data.groupby('customer_id').agg({\n",
    "    'ticket_id': 'count',\n",
    "    'issue_type': lambda x: ', '.join(set(x))\n",
    "}).rename(columns={'ticket_id': 'ticket_count', 'issue_type': 'issue_types'})\n",
    "\n",
    "# Combine all data horizontally\n",
    "customer_360 = pd.concat([crm_data.set_index('customer_id'),\n",
    "                          orders_summary,\n",
    "                          support_summary], \n",
    "                         axis=1, join='outer')\n",
    "\n",
    "print(\"\\nCustomer 360 View (horizontal concatenation):\")\n",
    "print(customer_360)\n",
    "\n",
    "# Strategy 2: Combine all data vertically (for data warehouse)\n",
    "all_customer_ids = pd.concat([\n",
    "    crm_data[['customer_id']],\n",
    "    orders_data[['customer_id']],\n",
    "    support_data[['customer_id']]\n",
    "]).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "print(\"\\nAll Unique Customer IDs (vertical concatenation):\")\n",
    "print(all_customer_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a6abd3",
   "metadata": {},
   "source": [
    "# Example 4.3: Financial Data Consolidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea8a4a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "REAL-WORLD EXAMPLE: FINANCIAL REPORT CONSOLIDATION\n",
      "================================================================================\n",
      "US Financials:\n",
      "  account_code     account_name    q1_us    q2_us\n",
      "0      REV-001    Product Sales  1000000  1100000\n",
      "1      REV-002  Service Revenue   250000   275000\n",
      "2     COGS-001        Materials   400000   420000\n",
      "3     COGS-002            Labor   300000   310000\n",
      "\n",
      "EU Financials:\n",
      "  account_code     account_name   q1_eu   q2_eu\n",
      "0      REV-001    Product Sales  800000  850000\n",
      "1      REV-002  Service Revenue  150000  160000\n",
      "2     COGS-001        Materials  300000  310000\n",
      "3     COGS-002            Labor  200000  210000\n",
      "\n",
      "Asia Financials:\n",
      "  account_code     account_name  q1_asia  q2_asia\n",
      "0      REV-001    Product Sales   600000   650000\n",
      "1      REV-002  Service Revenue   100000   110000\n",
      "2     COGS-001        Materials   250000   260000\n",
      "3     COGS-003         Shipping    50000    55000\n",
      "\n",
      "1. Regional Financial Comparison (horizontal):\n",
      "                 account_name      q1_us      q2_us     account_name  \\\n",
      "account_code                                                           \n",
      "REV-001         Product Sales  1000000.0  1100000.0    Product Sales   \n",
      "REV-002       Service Revenue   250000.0   275000.0  Service Revenue   \n",
      "COGS-001            Materials   400000.0   420000.0        Materials   \n",
      "COGS-002                Labor   300000.0   310000.0            Labor   \n",
      "COGS-003                  NaN        NaN        NaN              NaN   \n",
      "\n",
      "                 q1_eu     q2_eu     account_name   q1_asia   q2_asia  \n",
      "account_code                                                           \n",
      "REV-001       800000.0  850000.0    Product Sales  600000.0  650000.0  \n",
      "REV-002       150000.0  160000.0  Service Revenue  100000.0  110000.0  \n",
      "COGS-001      300000.0  310000.0        Materials  250000.0  260000.0  \n",
      "COGS-002      200000.0  210000.0              NaN       NaN       NaN  \n",
      "COGS-003           NaN       NaN         Shipping   50000.0   55000.0  \n",
      "\n",
      "2. Consolidated Financials (vertical - melted format):\n",
      "  account_code     account_name period_region   amount quarter region\n",
      "0      REV-001    Product Sales         q1_us  1000000      q1     us\n",
      "1      REV-002  Service Revenue         q1_us   250000      q1     us\n",
      "2     COGS-001        Materials         q1_us   400000      q1     us\n",
      "3     COGS-002            Labor         q1_us   300000      q1     us\n",
      "4      REV-001    Product Sales         q2_us  1100000      q2     us\n",
      "5      REV-002  Service Revenue         q2_us   275000      q2     us\n",
      "6     COGS-001        Materials         q2_us   420000      q2     us\n",
      "7     COGS-002            Labor         q2_us   310000      q2     us\n",
      "8      REV-001    Product Sales         q1_eu   800000      q1     eu\n",
      "9      REV-002  Service Revenue         q1_eu   150000      q1     eu\n",
      "\n",
      "3. Pivot Table from Consolidated Data:\n",
      "quarter                           q1                       q2                 \n",
      "region                          asia      eu       us    asia      eu       us\n",
      "account_code account_name                                                     \n",
      "COGS-001     Materials        250000  300000   400000  260000  310000   420000\n",
      "COGS-002     Labor                 0  200000   300000       0  210000   310000\n",
      "COGS-003     Shipping          50000       0        0   55000       0        0\n",
      "REV-001      Product Sales    600000  800000  1000000  650000  850000  1100000\n",
      "REV-002      Service Revenue  100000  150000   250000  110000  160000   275000\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"REAL-WORLD EXAMPLE: FINANCIAL REPORT CONSOLIDATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Financial data from different regions\n",
    "us_financials = pd.DataFrame({\n",
    "    'account_code': ['REV-001', 'REV-002', 'COGS-001', 'COGS-002'],\n",
    "    'account_name': ['Product Sales', 'Service Revenue', 'Materials', 'Labor'],\n",
    "    'q1_us': [1000000, 250000, 400000, 300000],\n",
    "    'q2_us': [1100000, 275000, 420000, 310000]\n",
    "})\n",
    "\n",
    "eu_financials = pd.DataFrame({\n",
    "    'account_code': ['REV-001', 'REV-002', 'COGS-001', 'COGS-002'],\n",
    "    'account_name': ['Product Sales', 'Service Revenue', 'Materials', 'Labor'],\n",
    "    'q1_eu': [800000, 150000, 300000, 200000],\n",
    "    'q2_eu': [850000, 160000, 310000, 210000]\n",
    "})\n",
    "\n",
    "asia_financials = pd.DataFrame({\n",
    "    'account_code': ['REV-001', 'REV-002', 'COGS-001', 'COGS-003'],  # Note: COGS-003 different\n",
    "    'account_name': ['Product Sales', 'Service Revenue', 'Materials', 'Shipping'],\n",
    "    'q1_asia': [600000, 100000, 250000, 50000],\n",
    "    'q2_asia': [650000, 110000, 260000, 55000]\n",
    "})\n",
    "\n",
    "print(\"US Financials:\")\n",
    "print(us_financials)\n",
    "print(\"\\nEU Financials:\")\n",
    "print(eu_financials)\n",
    "print(\"\\nAsia Financials:\")\n",
    "print(asia_financials)\n",
    "\n",
    "# Method 1: Horizontal concatenation by region\n",
    "regional_comparison = pd.concat([\n",
    "    us_financials.set_index('account_code'),\n",
    "    eu_financials.set_index('account_code'),\n",
    "    asia_financials.set_index('account_code')\n",
    "], axis=1)\n",
    "\n",
    "print(\"\\n1. Regional Financial Comparison (horizontal):\")\n",
    "print(regional_comparison)\n",
    "\n",
    "# Method 2: Vertical concatenation for consolidated P&L\n",
    "# First, melt each regional dataframe\n",
    "us_melted = us_financials.melt(id_vars=['account_code', 'account_name'],\n",
    "                               var_name='period_region',\n",
    "                               value_name='amount')\n",
    "us_melted[['quarter', 'region']] = us_melted['period_region'].str.split('_', expand=True)\n",
    "\n",
    "eu_melted = eu_financials.melt(id_vars=['account_code', 'account_name'],\n",
    "                               var_name='period_region',\n",
    "                               value_name='amount')\n",
    "eu_melted[['quarter', 'region']] = eu_melted['period_region'].str.split('_', expand=True)\n",
    "\n",
    "asia_melted = asia_financials.melt(id_vars=['account_code', 'account_name'],\n",
    "                                   var_name='period_region',\n",
    "                                   value_name='amount')\n",
    "asia_melted[['quarter', 'region']] = asia_melted['period_region'].str.split('_', expand=True)\n",
    "\n",
    "# Now concatenate vertically\n",
    "consolidated_financials = pd.concat([us_melted, eu_melted, asia_melted], ignore_index=True)\n",
    "\n",
    "print(\"\\n2. Consolidated Financials (vertical - melted format):\")\n",
    "print(consolidated_financials.head(10))\n",
    "\n",
    "# Create pivot table from consolidated data\n",
    "pivot_table = consolidated_financials.pivot_table(\n",
    "    index=['account_code', 'account_name'],\n",
    "    columns=['quarter', 'region'],\n",
    "    values='amount',\n",
    "    aggfunc='sum',\n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "print(\"\\n3. Pivot Table from Consolidated Data:\")\n",
    "print(pivot_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a222eb",
   "metadata": {},
   "source": [
    "# 5. Advanced Concatenation Techniques\n",
    "# Example 5.1: Concatenation with Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa983e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ADVANCED: CONCATENATION WITH SORTING\n",
      "================================================================================\n",
      "DataFrame 1 (unsorted):\n",
      "   A  B\n",
      "c  3  6\n",
      "a  1  4\n",
      "b  2  5\n",
      "\n",
      "DataFrame 2 (unsorted):\n",
      "   A   B\n",
      "f  9  12\n",
      "d  7  10\n",
      "e  8  11\n",
      "\n",
      "Concatenated and sorted by index:\n",
      "   A   B\n",
      "a  1   4\n",
      "b  2   5\n",
      "c  3   6\n",
      "d  7  10\n",
      "e  8  11\n",
      "f  9  12\n",
      "\n",
      "Concatenated and sorted by column A:\n",
      "   A   B\n",
      "1  1   4\n",
      "2  2   5\n",
      "0  3   6\n",
      "4  7  10\n",
      "5  8  11\n",
      "3  9  12\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ADVANCED: CONCATENATION WITH SORTING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create unsorted dataframes\n",
    "df1 = pd.DataFrame({\n",
    "    'A': [3, 1, 2],\n",
    "    'B': [6, 4, 5]\n",
    "}, index=['c', 'a', 'b'])\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "    'A': [9, 7, 8],\n",
    "    'B': [12, 10, 11]\n",
    "}, index=['f', 'd', 'e'])\n",
    "\n",
    "print(\"DataFrame 1 (unsorted):\")\n",
    "print(df1)\n",
    "print(\"\\nDataFrame 2 (unsorted):\")\n",
    "print(df2)\n",
    "\n",
    "# Concatenate and sort\n",
    "concatenated_sorted = pd.concat([df1, df2]).sort_index()\n",
    "print(\"\\nConcatenated and sorted by index:\")\n",
    "print(concatenated_sorted)\n",
    "\n",
    "# Sort by column after concatenation\n",
    "concatenated_sorted_col = pd.concat([df1, df2], ignore_index=True).sort_values('A')\n",
    "print(\"\\nConcatenated and sorted by column A:\")\n",
    "print(concatenated_sorted_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c593af9",
   "metadata": {},
   "source": [
    "# Example 5.2: Concatenation with Custom Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbf6d524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ADVANCED: CONCATENATION WITH CUSTOM INDEX HANDLING\n",
      "================================================================================\n",
      "Products 2023:\n",
      "         sales_2023\n",
      "product            \n",
      "A               100\n",
      "B               200\n",
      "C               150\n",
      "\n",
      "Products 2024:\n",
      "         sales_2024\n",
      "product            \n",
      "B               220\n",
      "C               170\n",
      "D                90\n",
      "\n",
      "1. Combined after reindexing:\n",
      "         sales_2023  sales_2024\n",
      "product                        \n",
      "A             100.0         NaN\n",
      "B             200.0       220.0\n",
      "C             150.0       170.0\n",
      "D               NaN        90.0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ADVANCED: CONCATENATION WITH CUSTOM INDEX HANDLING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create data with custom index\n",
    "products_2023 = pd.DataFrame({\n",
    "    'product': ['A', 'B', 'C'],\n",
    "    'sales_2023': [100, 200, 150]\n",
    "}).set_index('product')\n",
    "\n",
    "products_2024 = pd.DataFrame({\n",
    "    'product': ['B', 'C', 'D'],\n",
    "    'sales_2024': [220, 170, 90]\n",
    "}).set_index('product')\n",
    "\n",
    "print(\"Products 2023:\")\n",
    "print(products_2023)\n",
    "print(\"\\nProducts 2024:\")\n",
    "print(products_2024)\n",
    "\n",
    "# Method 1: Reindex before concatenation\n",
    "all_products = products_2023.index.union(products_2024.index)\n",
    "\n",
    "products_2023_reindexed = products_2023.reindex(all_products)\n",
    "products_2024_reindexed = products_2024.reindex(all_products)\n",
    "\n",
    "combined_reindexed = pd.concat([products_2023_reindexed, products_2024_reindexed], axis=1)\n",
    "print(\"\\n1. Combined after reindexing:\")\n",
    "print(combined_reindexed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8236cc",
   "metadata": {},
   "source": [
    "# Example 5.3: Concatenation with verify_integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08087dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ADVANCED: CONCATENATION WITH INTEGRITY CHECKING\n",
      "================================================================================\n",
      "DataFrame 1:\n",
      "   value\n",
      "a      1\n",
      "b      2\n",
      "c      3\n",
      "\n",
      "DataFrame 2 (with duplicate index 'c'):\n",
      "   value\n",
      "c      4\n",
      "d      5\n",
      "c      6\n",
      "\n",
      "1. Concatenated without verify_integrity (allows duplicates):\n",
      "   value\n",
      "a      1\n",
      "b      2\n",
      "c      3\n",
      "c      4\n",
      "d      5\n",
      "c      6\n",
      "\n",
      "2. With verify_integrity=True: Indexes have overlapping values: Index(['c'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ADVANCED: CONCATENATION WITH INTEGRITY CHECKING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create data with duplicate indices\n",
    "df_duplicate1 = pd.DataFrame({\n",
    "    'value': [1, 2, 3]\n",
    "}, index=['a', 'b', 'c'])\n",
    "\n",
    "df_duplicate2 = pd.DataFrame({\n",
    "    'value': [4, 5, 6]\n",
    "}, index=['c', 'd', 'c'])  # Note: duplicate 'c' index\n",
    "\n",
    "print(\"DataFrame 1:\")\n",
    "print(df_duplicate1)\n",
    "print(\"\\nDataFrame 2 (with duplicate index 'c'):\")\n",
    "print(df_duplicate2)\n",
    "\n",
    "# Without verify_integrity (default - allows duplicates)\n",
    "combined_default = pd.concat([df_duplicate1, df_duplicate2])\n",
    "print(\"\\n1. Concatenated without verify_integrity (allows duplicates):\")\n",
    "print(combined_default)\n",
    "\n",
    "# With verify_integrity (raises error on duplicates)\n",
    "try:\n",
    "    combined_integrity = pd.concat([df_duplicate1, df_duplicate2], verify_integrity=True)\n",
    "    print(combined_integrity)\n",
    "except ValueError as e:\n",
    "    print(f\"\\n2. With verify_integrity=True: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915b4f7f",
   "metadata": {},
   "source": [
    "# 6. Performance Considerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc9f6199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PERFORMANCE CONSIDERATIONS\n",
      "================================================================================\n",
      "Large DataFrames created: 100,000 rows each\n",
      "\n",
      "1. Vertical concatenation time: 0.0284 seconds\n",
      "   Result shape: (200000, 5)\n",
      "\n",
      "2. Horizontal concatenation time: 0.0104 seconds\n",
      "   Result shape: (100000, 4)\n",
      "\n",
      "3. Merge (alternative to horizontal concat): 0.0103 seconds\n",
      "   Result shape: (100000, 5)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PERFORMANCE CONSIDERATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "import time\n",
    "\n",
    "# Create large DataFrames for performance testing\n",
    "np.random.seed(42)\n",
    "n_rows = 100000\n",
    "\n",
    "large_df1 = pd.DataFrame({\n",
    "    'id': range(n_rows),\n",
    "    'value1': np.random.randn(n_rows),\n",
    "    'category1': np.random.choice(['A', 'B', 'C'], n_rows)\n",
    "})\n",
    "\n",
    "large_df2 = pd.DataFrame({\n",
    "    'id': range(n_rows, n_rows * 2),\n",
    "    'value2': np.random.randn(n_rows),\n",
    "    'category2': np.random.choice(['X', 'Y', 'Z'], n_rows)\n",
    "})\n",
    "\n",
    "large_df3 = pd.DataFrame({\n",
    "    'id': range(n_rows),\n",
    "    'value3': np.random.randn(n_rows),\n",
    "    'category3': np.random.choice(['M', 'N', 'O'], n_rows)\n",
    "})\n",
    "\n",
    "print(f\"Large DataFrames created: {n_rows:,} rows each\")\n",
    "\n",
    "# Test vertical concatenation performance\n",
    "start_time = time.time()\n",
    "vertical_result = pd.concat([large_df1, large_df2], ignore_index=True)\n",
    "vertical_time = time.time() - start_time\n",
    "print(f\"\\n1. Vertical concatenation time: {vertical_time:.4f} seconds\")\n",
    "print(f\"   Result shape: {vertical_result.shape}\")\n",
    "\n",
    "# Test horizontal concatenation performance\n",
    "start_time = time.time()\n",
    "horizontal_result = pd.concat([large_df1.set_index('id'), \n",
    "                               large_df3.set_index('id')], axis=1)\n",
    "horizontal_time = time.time() - start_time\n",
    "print(f\"\\n2. Horizontal concatenation time: {horizontal_time:.4f} seconds\")\n",
    "print(f\"   Result shape: {horizontal_result.shape}\")\n",
    "\n",
    "# Alternative: Using merge for horizontal combination\n",
    "start_time = time.time()\n",
    "merge_result = pd.merge(large_df1, large_df3, on='id')\n",
    "merge_time = time.time() - start_time\n",
    "print(f\"\\n3. Merge (alternative to horizontal concat): {merge_time:.4f} seconds\")\n",
    "print(f\"   Result shape: {merge_result.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eda71fb",
   "metadata": {},
   "source": [
    "# 7. Best Practices and Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4da6e27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "BEST PRACTICES AND COMMON PATTERNS\n",
      "================================================================================\n",
      "\n",
      "Data Collection Pattern:\n",
      "-----------------------\n",
      "# Collect data from multiple sources\n",
      "daily_data = []\n",
      "for file in daily_files:\n",
      "    df = pd.read_csv(file)\n",
      "    daily_data.append(df)\n",
      "# Concatenate all at once\n",
      "monthly_data = pd.concat(daily_data, ignore_index=True)\n",
      "\n",
      "Multi-Region Reporting Pattern:\n",
      "------------------------------\n",
      "# Combine regional reports\n",
      "regions = ['us', 'eu', 'asia']\n",
      "dfs = []\n",
      "for region in regions:\n",
      "    df = pd.read_excel(f'{region}_sales.xlsx')\n",
      "    df['region'] = region  # Add identifier\n",
      "    dfs.append(df)\n",
      "global_sales = pd.concat(dfs, ignore_index=True)\n",
      "\n",
      "Time Series Extension Pattern:\n",
      "-----------------------------\n",
      "# Extend time series with new data\n",
      "historical = pd.read_csv('historical_data.csv')\n",
      "new_data = pd.read_csv('new_data.csv')\n",
      "updated_series = pd.concat([historical, new_data])\n",
      "updated_series = updated_series.sort_values('date')\n",
      "\n",
      "Feature Engineering Pattern:\n",
      "---------------------------\n",
      "# Combine features from different sources\n",
      "customer_features = pd.concat([\n",
      "    demographics.set_index('customer_id'),\n",
      "    transaction_stats.set_index('customer_id'),\n",
      "    behavioral_data.set_index('customer_id')\n",
      "], axis=1, join='inner')  # Only customers with all data\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BEST PRACTICES AND COMMON PATTERNS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "patterns = [\n",
    "    (\"Data Collection Pattern\",\n",
    "     \"# Collect data from multiple sources\\n\"\n",
    "     \"daily_data = []\\n\"\n",
    "     \"for file in daily_files:\\n\"\n",
    "     \"    df = pd.read_csv(file)\\n\"\n",
    "     \"    daily_data.append(df)\\n\"\n",
    "     \"# Concatenate all at once\\n\"\n",
    "     \"monthly_data = pd.concat(daily_data, ignore_index=True)\"),\n",
    "    \n",
    "    (\"Multi-Region Reporting Pattern\",\n",
    "     \"# Combine regional reports\\n\"\n",
    "     \"regions = ['us', 'eu', 'asia']\\n\"\n",
    "     \"dfs = []\\n\"\n",
    "     \"for region in regions:\\n\"\n",
    "     \"    df = pd.read_excel(f'{region}_sales.xlsx')\\n\"\n",
    "     \"    df['region'] = region  # Add identifier\\n\"\n",
    "     \"    dfs.append(df)\\n\"\n",
    "     \"global_sales = pd.concat(dfs, ignore_index=True)\"),\n",
    "    \n",
    "    (\"Time Series Extension Pattern\",\n",
    "     \"# Extend time series with new data\\n\"\n",
    "     \"historical = pd.read_csv('historical_data.csv')\\n\"\n",
    "     \"new_data = pd.read_csv('new_data.csv')\\n\"\n",
    "     \"updated_series = pd.concat([historical, new_data])\\n\"\n",
    "     \"updated_series = updated_series.sort_values('date')\"),\n",
    "    \n",
    "    (\"Feature Engineering Pattern\",\n",
    "     \"# Combine features from different sources\\n\"\n",
    "     \"customer_features = pd.concat([\\n\"\n",
    "     \"    demographics.set_index('customer_id'),\\n\"\n",
    "     \"    transaction_stats.set_index('customer_id'),\\n\"\n",
    "     \"    behavioral_data.set_index('customer_id')\\n\"\n",
    "     \"], axis=1, join='inner')  # Only customers with all data\"),\n",
    "]\n",
    "\n",
    "for title, code in patterns:\n",
    "    print(f\"\\n{title}:\")\n",
    "    print(\"-\" * len(title))\n",
    "    print(code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ee7ccc",
   "metadata": {},
   "source": [
    "# 8. Quick Reference Cheat Sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "708efdc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "CONCATENATION CHEAT SHEET\n",
      "================================================================================\n",
      "\n",
      "BASIC SYNTAX:\n",
      "------------\n",
      "pd.concat([df1, df2])                    # Vertical (default)\n",
      "pd.concat([df1, df2], axis=0)            # Vertical (explicit)\n",
      "pd.concat([df1, df2], axis=1)            # Horizontal\n",
      "\n",
      "KEY PARAMETERS:\n",
      "--------------\n",
      "axis=0/1           # 0: vertical, 1: horizontal\n",
      "ignore_index=True  # Reset index after concatenation\n",
      "keys=['a', 'b']    # Create multi-level index\n",
      "names=['source']   # Name the index levels\n",
      "join='outer'       # 'outer' (default) or 'inner'\n",
      "sort=False         # Sort non-concatenation axis\n",
      "\n",
      "VERTICAL CONCATENATION USE CASES:\n",
      "--------------------------------\n",
      "1. Appending new rows to existing data\n",
      "2. Combining similar datasets from different sources\n",
      "3. Stacking time periods (months, quarters, years)\n",
      "4. Aggregating data from multiple files\n",
      "\n",
      "HORIZONTAL CONCATENATION USE CASES:\n",
      "----------------------------------\n",
      "1. Combining different features about same entities\n",
      "2. Merging data from different systems (CRM + ERP)\n",
      "3. Adding calculated columns to existing data\n",
      "4. Creating wide-format data for analysis\n",
      "\n",
      "ALTERNATIVES TO CONCAT:\n",
      "---------------------\n",
      "# For vertical concatenation:\n",
      "df1.append(df2)           # Similar to concat, but deprecated\n",
      "pd.concat([df1, df2])     # Preferred method\n",
      "\n",
      "# For horizontal concatenation:\n",
      "pd.merge(df1, df2, on='key')    # SQL-like join\n",
      "df1.join(df2, how='inner')      # Join on index\n",
      "pd.concat([df1, df2], axis=1)   # Simple column binding\n",
      "\n",
      "PERFORMANCE TIPS:\n",
      "---------------\n",
      "1. Use ignore_index=True for vertical concat to avoid index issues\n",
      "2. Pre-sort data before horizontal concat if joining on index\n",
      "3. Use merge() instead of concat() for complex horizontal combinations\n",
      "4. Concatenate in batches for very large datasets\n",
      "5. Use keys parameter to track data sources\n",
      "\n",
      "COMMON PITFALLS:\n",
      "--------------\n",
      "1. Duplicate indices causing unexpected results\n",
      "2. Misaligned columns creating NaN values\n",
      "3. Memory issues with very large concatenations\n",
      "4. Forgetting to reset index after vertical concatenation\n",
      "5. Incorrect axis parameter (0 vs 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CONCATENATION CHEAT SHEET\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "cheat_sheet = \"\"\"\n",
    "BASIC SYNTAX:\n",
    "------------\n",
    "pd.concat([df1, df2])                    # Vertical (default)\n",
    "pd.concat([df1, df2], axis=0)            # Vertical (explicit)\n",
    "pd.concat([df1, df2], axis=1)            # Horizontal\n",
    "\n",
    "KEY PARAMETERS:\n",
    "--------------\n",
    "axis=0/1           # 0: vertical, 1: horizontal\n",
    "ignore_index=True  # Reset index after concatenation\n",
    "keys=['a', 'b']    # Create multi-level index\n",
    "names=['source']   # Name the index levels\n",
    "join='outer'       # 'outer' (default) or 'inner'\n",
    "sort=False         # Sort non-concatenation axis\n",
    "\n",
    "VERTICAL CONCATENATION USE CASES:\n",
    "--------------------------------\n",
    "1. Appending new rows to existing data\n",
    "2. Combining similar datasets from different sources\n",
    "3. Stacking time periods (months, quarters, years)\n",
    "4. Aggregating data from multiple files\n",
    "\n",
    "HORIZONTAL CONCATENATION USE CASES:\n",
    "----------------------------------\n",
    "1. Combining different features about same entities\n",
    "2. Merging data from different systems (CRM + ERP)\n",
    "3. Adding calculated columns to existing data\n",
    "4. Creating wide-format data for analysis\n",
    "\n",
    "ALTERNATIVES TO CONCAT:\n",
    "---------------------\n",
    "# For vertical concatenation:\n",
    "df1.append(df2)           # Similar to concat, but deprecated\n",
    "pd.concat([df1, df2])     # Preferred method\n",
    "\n",
    "# For horizontal concatenation:\n",
    "pd.merge(df1, df2, on='key')    # SQL-like join\n",
    "df1.join(df2, how='inner')      # Join on index\n",
    "pd.concat([df1, df2], axis=1)   # Simple column binding\n",
    "\n",
    "PERFORMANCE TIPS:\n",
    "---------------\n",
    "1. Use ignore_index=True for vertical concat to avoid index issues\n",
    "2. Pre-sort data before horizontal concat if joining on index\n",
    "3. Use merge() instead of concat() for complex horizontal combinations\n",
    "4. Concatenate in batches for very large datasets\n",
    "5. Use keys parameter to track data sources\n",
    "\n",
    "COMMON PITFALLS:\n",
    "--------------\n",
    "1. Duplicate indices causing unexpected results\n",
    "2. Misaligned columns creating NaN values\n",
    "3. Memory issues with very large concatenations\n",
    "4. Forgetting to reset index after vertical concatenation\n",
    "5. Incorrect axis parameter (0 vs 1)\n",
    "\"\"\"\n",
    "\n",
    "print(cheat_sheet)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
